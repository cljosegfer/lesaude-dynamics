{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83ddeb20",
   "metadata": {},
   "source": [
    "# setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "566aadce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "528dea1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath('..'))\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "from hparams import DATA_ROOT\n",
    "from dataset import DynamicsDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74739a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "WAVE_PATH = os.path.join(DATA_ROOT, 'mimic_iv_ecg_waveforms.h5')\n",
    "LABEL_PATH = os.path.join(DATA_ROOT, 'mimic_iv_ecg_icd.h5')\n",
    "META_PATH = os.path.join(DATA_ROOT, 'metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4b80828",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(META_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c9d020",
   "metadata": {},
   "source": [
    "# trn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de809a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Dataset from /home/remote/Documents/datasets/lesaude/mimic-iv-ecg-monolith/mimic_iv_ecg_waveforms.h5...\n",
      "   Loading Subject IDs for integrity check...\n",
      "   > Integrity Check Passed: Waveform and Label files are perfectly aligned.\n",
      "   Loading Study IDs for integrity check...\n"
     ]
    }
   ],
   "source": [
    "ds_train = DynamicsDataset(\n",
    "    split='train',\n",
    "    return_pairs=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cff4bfcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Dataset from /home/remote/Documents/datasets/lesaude/mimic-iv-ecg-monolith/mimic_iv_ecg_waveforms.h5...\n",
      "   Loading Subject IDs for integrity check...\n",
      "   > Integrity Check Passed: Waveform and Label files are perfectly aligned.\n",
      "   Loading Study IDs for integrity check...\n",
      "   Scanning for action types...\n",
      "   > Total Pairs: 575784\n",
      "   > Stable Pairs: 420018\n",
      "   > Changed Pairs: 155766\n"
     ]
    }
   ],
   "source": [
    "ds_train = DynamicsDataset(\n",
    "    split='train',\n",
    "    return_pairs=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31899082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows in CSV (Folds 0-17): 721002\n",
      "Valid Pairs in Dataset:   575784\n"
     ]
    }
   ],
   "source": [
    "target_folds = list(range(0, 18))\n",
    "df_train_raw = df[df['fold'].isin(target_folds)]\n",
    "\n",
    "print(f\"Rows in CSV (Folds 0-17): {len(df_train_raw)}\")\n",
    "print(f\"Valid Pairs in Dataset:   {len(ds_train)}\")\n",
    "\n",
    "expected_max = len(df_train_raw)\n",
    "assert len(ds_train) < expected_max, \"Error: Dataset has more pairs than rows!\"\n",
    "assert len(ds_train) > expected_max * 0.5, \"Error: Too many pairs lost! Check alignment.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a51b92f",
   "metadata": {},
   "source": [
    "# val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2c11440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Dataset from /home/remote/Documents/datasets/lesaude/mimic-iv-ecg-monolith/mimic_iv_ecg_waveforms.h5...\n",
      "   Loading Subject IDs for integrity check...\n",
      "   > Integrity Check Passed: Waveform and Label files are perfectly aligned.\n",
      "   Loading Study IDs for integrity check...\n",
      "   Scanning for action types...\n",
      "   > Total Pairs: 31397\n",
      "   > Stable Pairs: 22753\n",
      "   > Changed Pairs: 8644\n"
     ]
    }
   ],
   "source": [
    "ds_val = DynamicsDataset(\n",
    "    split='val',\n",
    "    return_pairs=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e31dc99d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   > Applying Baseline Filter: Keeping only first ECG per stay (ecg_no_within_stay == 0)\n",
      "   > Reduced 39464 -> 14456 records.\n",
      "Initializing Dataset from /home/remote/Documents/datasets/lesaude/mimic-iv-ecg-monolith/mimic_iv_ecg_waveforms.h5...\n",
      "   Loading Subject IDs for integrity check...\n",
      "   > Integrity Check Passed: Waveform and Label files are perfectly aligned.\n",
      "   Loading Study IDs for integrity check...\n"
     ]
    }
   ],
   "source": [
    "ds_val = DynamicsDataset(\n",
    "    split='val',\n",
    "    return_pairs=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f4c1f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manual Count (Fold 18 & First ECG): 14456\n",
      "Dataset Count:                      14456\n",
      "✅ Validation Filter (First ECG) is working perfectly.\n"
     ]
    }
   ],
   "source": [
    "df_val_filtered = df[(df['fold'] == 18) & (df['ecg_no_within_stay'] == 0)]\n",
    "\n",
    "print(f\"Manual Count (Fold 18 & First ECG): {len(df_val_filtered)}\")\n",
    "print(f\"Dataset Count:                      {len(ds_val)}\")\n",
    "\n",
    "if len(ds_val) == len(df_val_filtered):\n",
    "    print(\"✅ Validation Filter (First ECG) is working perfectly.\")\n",
    "else:\n",
    "    print(\"❌ Validation Count Mismatch! Check the __init__ filtering logic.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1aba74a",
   "metadata": {},
   "source": [
    "# tst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a74e97cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Dataset from /home/remote/Documents/datasets/lesaude/mimic-iv-ecg-monolith/mimic_iv_ecg_waveforms.h5...\n",
      "   Loading Subject IDs for integrity check...\n",
      "   > Integrity Check Passed: Waveform and Label files are perfectly aligned.\n",
      "   Loading Study IDs for integrity check...\n",
      "   Scanning for action types...\n",
      "   > Total Pairs: 31502\n",
      "   > Stable Pairs: 23071\n",
      "   > Changed Pairs: 8431\n"
     ]
    }
   ],
   "source": [
    "ds_test = DynamicsDataset(\n",
    "    split='test',\n",
    "    return_pairs=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7adbfc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   > Applying Baseline Filter: Keeping only first ECG per stay (ecg_no_within_stay == 0)\n",
      "   > Reduced 39569 -> 14237 records.\n",
      "Initializing Dataset from /home/remote/Documents/datasets/lesaude/mimic-iv-ecg-monolith/mimic_iv_ecg_waveforms.h5...\n",
      "   Loading Subject IDs for integrity check...\n",
      "   > Integrity Check Passed: Waveform and Label files are perfectly aligned.\n",
      "   Loading Study IDs for integrity check...\n"
     ]
    }
   ],
   "source": [
    "ds_test = DynamicsDataset(\n",
    "    split='test',\n",
    "    return_pairs=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5bc80db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manual Count (Fold 19 & First ECG): 14237\n",
      "Dataset Count:                      14237\n",
      "✅ Test Split working perfectly.\n"
     ]
    }
   ],
   "source": [
    "df_test_filtered = df[(df['fold'] == 19) & (df['ecg_no_within_stay'] == 0)]\n",
    "\n",
    "print(f\"Manual Count (Fold 19 & First ECG): {len(df_test_filtered)}\")\n",
    "print(f\"Dataset Count:                      {len(ds_test)}\")\n",
    "\n",
    "assert len(ds_test) == len(df_test_filtered)\n",
    "print(\"✅ Test Split working perfectly.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f21dbbb",
   "metadata": {},
   "source": [
    "# patient leak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aeda3f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subjects(dataset):\n",
    "    # Helper to read subjects from the valid indices of the dataset\n",
    "    indices = dataset.valid_indices\n",
    "    with h5py.File(WAVE_PATH, 'r') as f:\n",
    "        # We assume indices are sorted, so we can use fancy indexing or just read all and mask\n",
    "        # Reading all is faster for integrity checks if RAM allows\n",
    "        all_subjs = f['subject_id'][:]\n",
    "    return set(all_subjs[indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fdea696a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Subject IDs from Datasets...\n",
      "Unique Patients - Train: 93627\n",
      "Unique Patients - Val:   6212\n",
      "Unique Patients - Test:  6175\n",
      "✅ PASS: Zero Patient Leakage detected.\n"
     ]
    }
   ],
   "source": [
    "print(\"Extracting Subject IDs from Datasets...\")\n",
    "train_subjs = get_subjects(ds_train)\n",
    "val_subjs = get_subjects(ds_val)\n",
    "test_subjs = get_subjects(ds_test)\n",
    "\n",
    "print(f\"Unique Patients - Train: {len(train_subjs)}\")\n",
    "print(f\"Unique Patients - Val:   {len(val_subjs)}\")\n",
    "print(f\"Unique Patients - Test:  {len(test_subjs)}\")\n",
    "\n",
    "# Intersections\n",
    "train_val_leak = train_subjs.intersection(val_subjs)\n",
    "train_test_leak = train_subjs.intersection(test_subjs)\n",
    "val_test_leak = val_subjs.intersection(test_subjs)\n",
    "\n",
    "if len(train_val_leak) == 0 and len(train_test_leak) == 0 and len(val_test_leak) == 0:\n",
    "    print(\"✅ PASS: Zero Patient Leakage detected.\")\n",
    "else:\n",
    "    print(\"❌ FAIL: Leakage detected!\")\n",
    "    print(f\"Train/Val Overlap: {len(train_val_leak)}\")\n",
    "    print(f\"Train/Test Overlap: {len(train_test_leak)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25eb8cf6",
   "metadata": {},
   "source": [
    "# loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "637b0ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   > Applying Baseline Filter: Keeping only first ECG per stay (ecg_no_within_stay == 0)\n",
      "   > Reduced 39569 -> 14237 records.\n",
      "Initializing Dataset from /home/remote/Documents/datasets/lesaude/mimic-iv-ecg-monolith/mimic_iv_ecg_waveforms.h5...\n",
      "   Loading Subject IDs for integrity check...\n",
      "   > Integrity Check Passed: Waveform and Label files are perfectly aligned.\n",
      "   Loading Study IDs for integrity check...\n"
     ]
    }
   ],
   "source": [
    "# dl = DataLoader(ds_train, batch_size=4, shuffle=True)\n",
    "\n",
    "# ds_val = DynamicsDataset(\n",
    "#     split='val',\n",
    "#     return_pairs=True\n",
    "# )\n",
    "# dl = DataLoader(ds_val, batch_size=4, )\n",
    "\n",
    "ds_test = DynamicsDataset(\n",
    "    split='test',\n",
    "    return_pairs=False\n",
    ")\n",
    "dl = DataLoader(ds_test, batch_size=4, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5dd309ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch in tqdm(dl):\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab36766f",
   "metadata": {},
   "source": [
    "# patient leak old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee577a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b4c73e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subjects_subset(subset):\n",
    "    \"\"\"\n",
    "    Extracts Subject IDs from a PyTorch Subset object created by random_split.\n",
    "    \"\"\"\n",
    "    # 1. Access the parent dataset (DynamicsDataset)\n",
    "    parent_dataset = subset.dataset\n",
    "    \n",
    "    # 2. Get the list of indices assigned to this split\n",
    "    # These indices refer to the parent_dataset, NOT the HDF5 rows directly yet\n",
    "    subset_indices = subset.indices\n",
    "    \n",
    "    # 3. Map these to the Real HDF5 Rows\n",
    "    # parent_dataset.valid_indices converts (0..N) -> (Real HDF5 Row)\n",
    "    real_hdf5_indices = parent_dataset.valid_indices[subset_indices]\n",
    "    \n",
    "    # 4. Read Subject IDs from disk (or RAM if loaded)\n",
    "    # Since subject_id array is small (~1.5MB), reading all is fastest\n",
    "    with h5py.File(parent_dataset.wave_path, 'r') as f:\n",
    "        all_subjects = f['subject_id'][:]\n",
    "        \n",
    "    # 5. Extract the specific subjects for this split\n",
    "    subjects_in_split = all_subjects[real_hdf5_indices]\n",
    "    \n",
    "    # Return unique subjects\n",
    "    return set(subjects_in_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7d901ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Dataset from /home/remote/Documents/datasets/lesaude/mimic-iv-ecg-monolith/mimic_iv_ecg_waveforms.h5...\n",
      "   Loading Subject IDs for integrity check...\n",
      "   > Integrity Check Passed: Waveform and Label files are perfectly aligned.\n",
      "   Loading Study IDs for integrity check...\n"
     ]
    }
   ],
   "source": [
    "full_dataset = DynamicsDataset(\n",
    "    waveform_h5_path=os.path.join(DATA_ROOT, 'mimic_iv_ecg_waveforms.h5'),\n",
    "    label_h5_path=os.path.join(DATA_ROOT, 'mimic_iv_ecg_icd.h5'),\n",
    "    return_pairs=False  # Crucial: Returns (x, y)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "016e912c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(42)\n",
    "# full_dataset.valid_indices = full_dataset.valid_indices[rng.choice(total, keep, replace=False)]\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "train_ds, val_ds = random_split(full_dataset, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fd33aa16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Subject IDs from Datasets...\n",
      "Unique Patients - Train: 133834\n",
      "Unique Patients - Val:   68618\n",
      "❌ FAIL: Leakage detected!\n",
      "Train/Val Overlap: 57234\n"
     ]
    }
   ],
   "source": [
    "print(\"Extracting Subject IDs from Datasets...\")\n",
    "train_subjs = get_subjects_subset(train_ds)\n",
    "val_subjs = get_subjects_subset(val_ds)\n",
    "\n",
    "print(f\"Unique Patients - Train: {len(train_subjs)}\")\n",
    "print(f\"Unique Patients - Val:   {len(val_subjs)}\")\n",
    "\n",
    "# Intersections\n",
    "train_val_leak = train_subjs.intersection(val_subjs)\n",
    "\n",
    "if len(train_val_leak) == 0:\n",
    "    print(\"✅ PASS: Zero Patient Leakage detected.\")\n",
    "else:\n",
    "    print(\"❌ FAIL: Leakage detected!\")\n",
    "    print(f\"Train/Val Overlap: {len(train_val_leak)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eb7af5e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "PATIENT LEAKAGE REPORT\n",
      "========================================\n",
      "Patients found in BOTH Train and Val: 57,234\n",
      "Leakage Percentage (relative to Val): 83.41%\n",
      "CONCLUSION: The high AUROC (0.81) in Experiment A was due to memorizing these patients.\n"
     ]
    }
   ],
   "source": [
    "intersection = train_subjs.intersection(val_subjs)\n",
    "\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"PATIENT LEAKAGE REPORT\")\n",
    "print(\"=\"*40)\n",
    "print(f\"Patients found in BOTH Train and Val: {len(intersection):,}\")\n",
    "\n",
    "if len(intersection) > 0:\n",
    "    print(f\"Leakage Percentage (relative to Val): {len(intersection) / len(val_subjs):.2%}\")\n",
    "    print(\"CONCLUSION: The high AUROC (0.81) in Experiment A was due to memorizing these patients.\")\n",
    "else:\n",
    "    print(\"CONCLUSION: No leakage found (Unexpected for random_split).\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dynamics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
